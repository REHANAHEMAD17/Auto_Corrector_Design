{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce189a4-62eb-4d85-af7c-2b63ec9bb56c",
   "metadata": {},
   "source": [
    "### 1.- Steps to build the spelling corrector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e05ed2-ab4b-4acb-8606-242f9f5d5f6e",
   "metadata": {},
   "source": [
    "#### a) Mounting the drive and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eaaf23-d27e-4f7f-b272-6b2d1b171712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOunting the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ca3df-e5d4-4721-a05a-8b583fc14ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "mounted at /content/drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339420dc-33f7-4761-a06d-00f268cce5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importring the librarires\n",
    "import re\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21cc6b7a-9029-44cf-9962-cbf2b2a7055c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2637075051.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    file= open('C:\\Users\\DELL E7480\\OneDrive\\Desktop\\New Text Document.txt').read()\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# Reading the Dataset\n",
    "file= open('/content/drive/MyDrive/NLP/big.txt').read()\n",
    "\n",
    "#content of the file\n",
    "\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066df2e-ecbc-4a01-9f57-3824bea86cb0",
   "metadata": {},
   "source": [
    "### 2) - Pre-processing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d4f05-468c-4c37-934e-cb6be4f7e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d9376-dd91-435b-8927-bf7781f36962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the words and counting the frequecny\n",
    "\n",
    "WORDS= Counter(words(file))\n",
    "WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180b6a2-9fe4-48b0-a2b1-470a0084b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6860e73-7964-410f-b693-c89ec236468c",
   "metadata": {},
   "source": [
    "### 3)- Generating the candidate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f0fea-b2cc-4009-ab7c-c501401c6d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the samples word\n",
    "\n",
    "word= 'haw'\n",
    "\n",
    "\n",
    "splits= []\n",
    "for i in range(len(word) + 1):\n",
    "    splits.append(word[:i], word[i:]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b3c60-0b6d-45fc-b3d5-4ad9492f260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe9acd-4ec7-4b7f-bd4e-9e624313c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All poosible letter that will be used for generate candidate words\n",
    "\n",
    "\n",
    "letters= 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "# Generating the candidtes after insertion of a letter\n",
    "\n",
    "insertion= []\n",
    "for sw1, sw2 in splits:\n",
    "    for j in letters:\n",
    "        insertion.append(sw1 + j + sw2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa0513-cb5a-4d33-8f9b-4f5bb6f2e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate after the insertion\n",
    "print(insertion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98c470-f0e2-4362-a31b-27e2a8c89acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation candidates after the deletation of a letter\n",
    "deletion= \n",
    "for sw1, sw2 in splits:\n",
    "    if sw2:\n",
    "        deletion.append(sw1 + sw2[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d727f-4a65-49fe-b544-247116e9ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deletion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfc7de-d373-4a5e-878c-99e0ae16aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the candidates after subtitution of a letter\n",
    "\n",
    "substitution= []\n",
    "for sw1, sw2 in splits:\n",
    "    if sw2:\n",
    "        for c in letter:\n",
    "            substitution.append(sw1 + c+ sw2[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27decd6-f38c-4237-8597-7fef41ea702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25672100-0f9b-4299-9515-aee834a2dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generationg the candidates after the transposition of two adjecent letters\n",
    "\n",
    "transpose= []\n",
    "\n",
    "for sw1, sw2 in splits:\n",
    "    if len(sw2) > 1:\n",
    "        transpose.append(sw1 + sw2[1] + sw2[0] + sw2 [2:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7058dbe3-c931-4c31-a5b0-9831ee5123cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidates after the transposition\n",
    "transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61106a-4302-43e0-83ee-04e67217f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All generated candidates fr a word\n",
    "\n",
    "set(insetion + deletion + substituion + transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26af29a-b8c5-49f8-b23f-efd447167a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defing the function to generate the all candidates that are edit distance from the origin word \n",
    "\n",
    "def edits1(word):\n",
    "    splits= [(word[:i]), word[i:]]) for i in range(len(word) + 1)]\n",
    "     # Genrationg the candidates after the insertion of a letter\n",
    "    insertion= [sw1 + c+ sw2     for sw1 ,sw2 in splits for c in letters]\n",
    "    # Generationg the candidates after the deletion of a letter\n",
    "    deletion= [ sw1 + sw2 [1:]    for sw1, sw2 in splits if sw2]\n",
    "    # Generationg the candidates after the substitution of a letter\n",
    "    substitution= [ sw1 + c+ sw2 [1:]    for sw1, sw2 in splits if sw2 for c in letters]\n",
    "    # Generating the candidates after the transposition of two adjacent letters\n",
    "    transpose= [sw1 + sw2[1] + sw2[0] + sw2[2: ] for sw1, sw2 in splits if splits if len(sw2) > 1]\n",
    "    # Returning the all generated candidates for a word\n",
    "    return set(deletion + insertion + substitution + transpose)\n",
    "    \n",
    "\n",
    "# generating the samples words\n",
    "edits1('the')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e3d03-7b55-4eb3-b860-e52dde856765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of the generated candidates for a samples word\n",
    "len(edits1('the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7177230-7bdd-47ee-aaba-af50b93a6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of the generated candidates for a samples word\n",
    "len(edits1('lanuages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc981ff-eaeb-4b9e-8d24-be3cfeba6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to keep only those candidates which are present in the vocabulary \n",
    "def known(words):\n",
    "    return set(w for w in words if w in WORDS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff356940-10f0-4edf-ab2e-1a148a72340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "known(edits1('lanuages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4cb962-b0b2-4fec-98bd-320242463beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "known(edits1('the'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f909dd51-6921-472f-9049-8bc3b496232b",
   "metadata": {},
   "source": [
    "### 4) -Defining the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b185fd3-05d7-475b-85e5-fd45027ee5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total no of the words in the file\n",
    "sum(WORDS.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1959cd-608a-48da-aad8-26bfbe3c6838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63083ec3-3c1c-42a4-96ad-a66eb8f3770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to return the probabilityof a words\n",
    "def P (word, N= sum(WORDS.values())):\n",
    "    return WORDS[word] / N\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112877a8-2bfe-4704-bd6c-46a9636bdf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of sampling word\n",
    "P('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ee86d-4e57-4921-8c0c-986183b2a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "P('how')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc69d5-974d-4cef-8419-9cfd84fb69b6",
   "metadata": {},
   "source": [
    "### 5. Defining the channel model\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9b8ab0f-b3f4-4147-8126-09a664b1605f",
   "metadata": {},
   "source": [
    "Return a word if:\n",
    "    1. It is know, else\n",
    "    2. Its is 1 edit distance away from the original word, else\n",
    "    3. Original word even if it's not known\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b3255-cfa4-40ad-8dcc-280aa41f7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate the candidates\n",
    "\n",
    "def candidates(word):\n",
    "    return list(known([word])) or list(known(edits1(word1)))) or [word]\n",
    "\n",
    "\n",
    "candidates('lanuage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b58dc8-f203-41d8-a675-fa9ac59323b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generationg the candidates for a sample word\n",
    "candidates('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d4f57-7cd2-4028-8604-4d1b0c81ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates('lave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2aeaf5-2ad4-4cb9-8842-b7e24989dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pick the best word out of the generated candidates\n",
    "def correction(word):\n",
    "    return max(candidates(word), key = P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa019a63-38f0-437e-b2a6-8461ffa18895",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction('lave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780ba70-2b08-4273-9638-f0dc75713140",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction ('pemission')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6c705-7c04-43b7-986a-89b409ea6501",
   "metadata": {},
   "source": [
    "### 6)- Auto Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3aa99-6002-423e-bc75-9aa514d82ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    1. Take a sentence as input\n",
    "    2. Generated tokens from the sentence\n",
    "    3. fr each token , generate candidates words and return the corrected word\n",
    "    4. Return the auto corrected sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbb105-8349-4e6e-9180-aeb2f53edaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sentence\n",
    "\n",
    "sentense= 'how arq yu'\n",
    "\n",
    "\n",
    "# generated tokens from the sentence\n",
    "tokens= sentense.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca482fc-7b4f-45b2-bce4-bd18d7aeba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the candidates and returning the corrected words for each token \n",
    "corrected_sentence= []\n",
    "for i in range(len(token)):\n",
    "    corrected_token= correction(token[i])\n",
    "    corrected_sentence.append(corrected_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79af95a-631b-4773-8791-ce72d1b9acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # corrected tokens\n",
    "\n",
    "corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bd77b-d9e2-4562-8805-3591ee4905fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto corrected sentense\n",
    "\" \".join(corrected_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f5749-fe04-413a-9df7-5c67f94f0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the auto corrected sentense'\n",
    "def sentence_corrector(sentence):\n",
    "    sentence= sentence.lower()\n",
    "    tokens= sentence.split()\n",
    "    corrected_sentence= []\n",
    "    for  i in range(len(tokens)):\n",
    "        corrected_token = correction(token[i])\n",
    "        corrected_sentence.append(corrected_token)\n",
    "\n",
    "    return \" \".join (corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a8ad51-5807-44fd-a636-cf8bf97595ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_corrector('natural lanuag pocesing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712b3e0-8723-43d1-983b-a38be51b6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto correcting the samples sentences\n",
    "sentence_corrector('i am diing gret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b26021-ca0b-4d0d-bc12-bc67ffc3cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_corrector('are you alrikht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2db1f-f92c-4598-a90a-5bbfa8715fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_corrector('are you foing to the pty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968aa5e-8b66-4f1d-b4be-699e9820ba05",
   "metadata": {},
   "source": [
    "## Note : Final At last generation of these autocorrect model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e7aa0-dc5c-4a13-831b-695b53053719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Auto correcting the sample sentences\n",
    "sentence_corrector('this is a big sigin fr us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba835a39-7cc6-4e9d-9d40-de2b885202d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_corrector('i like ho verstil acres she is')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
